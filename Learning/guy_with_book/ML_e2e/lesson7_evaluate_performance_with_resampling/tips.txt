 Generally k-fold cross validation is the gold standard for evaluating the performance of a
machine learning algorithm on unseen data with k set to 3, 5, or 10.

 Using a train/test split is good for speed when using a slow algorithm and produces
performance estimates with lower bias when using large datasets.

 Techniques like leave-one-out cross validation and repeated random splits can be useful
intermediates when trying to balance variance in the estimated performance, model
training speed and dataset size.

The best advice is to experiment and find a technique for your problem that is fast and
produces reasonable estimates of performance that you can use to make decisions. If in doubt,
use 10-fold cross validation.
